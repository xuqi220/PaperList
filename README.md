
# LegalAI

### * Survey

### * Dataset

### * Legal Judgment Prediction

### * Court View Generation

Event Grounded Criminal Court View Generation with Cooperative (Large) Language Models,2024.[[sigir](https://arxiv.org/abs/2404.07001)]

Explaining legal judgments: A multitask learning framework for enhancing factual consistency in rationale generation,2023.[[paper](https://www.sciencedirect.com/science/article/pii/S1319157823004226)]

Circumstances enhanced Criminal Court View Generation,2021.[[sigir](https://dl.acm.org/doi/abs/10.1145/3404835.3462984)]

Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions,2018,[[naacl](https://aclanthology.org/N18-1168/)]

### * Similar Case Match

### * LLM in Law

DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services,2023. [[paper](https://arxiv.org/abs/2309.11325)]

Lawyer LLaMA Technical Report,2023.[[paper](https://arxiv.org/abs/2305.15062)]

### * Study

A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction,2023. [[paper](https://aclanthology.org/2023.findings-emnlp.490/)]

LawBench: Benchmarking Legal Knowledge of Large Language Models,2023. [[paper](https://arxiv.org/abs/2309.16289)]

LAiW: A Chinese Legal Large Language Models Benchmark,2024. [[paper](https://openreview.net/pdf?id=HEjqNfHCCH)]

TruthfulQA: Measuring How Models Mimic Human Falsehoods,2022. [[paper](https://aclanthology.org/2022.acl-long.229.pdf)]

**Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models,2024.** [[paper](https://arxiv.org/abs/2401.01301)]

# Large Language Model

### * Survey

Leveraging Large Language Models for NLG Evaluation:
Advances and Challenges,2024.[[paper](https://arxiv.org/abs/2401.07103)]

A Survey on Efficient Inference for Large
Language Models,2024.[[paper](https://arxiv.org/abs/2404.14294)]

### * Models
QWEN TECHNICAL REPORT [[paper](https://arxiv.org/abs/2309.16609)]

GLM: General Language Model Pretraining with Autoregressive Blank Infilling [[paper](https://aclanthology.org/2022.acl-long.26.pdf)]

LLaMA: Open and Efficient Foundation Language Models [[paper](https://arxiv.org/abs/2302.13971)]

Llama 2: Open Foundation and Fine-Tuned Chat Models [[paper](https://arxiv.org/abs/2307.09288)]

Introducing Meta Llama 3: The most capable openly available LLM to date [[paper](https://ai.meta.com/blog/meta-llama-3/)]

### * Long-tail & Few-shot

Making Pretrained Language Models Good Long-tailed Learners,2022.[[EMNLP](https://aclanthology.org/2022.emnlp-main.217.pdf)]

Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples! 2023.[[EMNLP](https://aclanthology.org/2023.findings-emnlp.710.pdf)]

Large Language Models Struggle to Learn Long-Tail Knowledge.[[ICML](https://proceedings.mlr.press/v202/kandpal23a/kandpal23a.pdf)]

On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models[[ACL](https://aclanthology.org/2024.acl-short.12.pdf)]


### * Rule-based Reasoning

Chain of Logic: Rule-Based Reasoning with Large Language Models,2024.[[ACL](https://aclanthology.org/2024.findings-acl.159.pdf)]

Large Language Models can Learn Rules,2024.[[paper](https://arxiv.org/abs/2310.07064)]

Case-Based or Rule-Based: How Do Transformers Do the Math? 2024,[[ICML](https://arxiv.org/abs/2402.17709)].

Enabling Large Language Models to Learn from Rules,2023. [[paper](https://arxiv.org/pdf/2311.08883v2)]

### * Retriever Argument Generation（RAG）

Self-Knowledge Guided Retrieval Augmentation
for Large Language Models,2023[[EMNLP](https://aclanthology.org/2023.findings-emnlp.691/)]

Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy,2023.[[EMNLP](https://aclanthology.org/2023.findings-emnlp.620/)]

Retrieval-Generation Synergy Augmented Large Language Models,2023.[[paper](https://arxiv.org/abs/2310.05149)]

### * PLan-then-Generate
Plan-then-Generate: Controlled Data-to-Text Generation via Planning,2021.[[paper](https://aclanthology.org/2021.findings-emnlp.76/)]

Interpretable Math Word Problem Solution Generation
Via Step-by-step Planning,2023. [[paper](https://aclanthology.org/2023.acl-long.379/)]

### * Generated with Citations

Citation-Enhanced Generation for LLM-based Chatbots,2024.[[ACL](https://aclanthology.org/2024.acl-long.79)]

Training Language Models to Generate Text with Citations via Fine-grained Rewards,2024.[[ACL](https://arxiv.org/pdf/2402.04315)]

Chain-of-Thought Improves Text Generation with Citations in Large Language Models,2024.[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29794)]

Learning to Plan and Generate Text with Citations,2024.[[paper](https://arxiv.org/abs/2404.03381)]

Enabling Large Language Models to Generate Text with Citations,2023.[[paper](https://aclanthology.org/2023.emnlp-main.398/)]



### * Chain-of-Thought (CoT)

Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,2023. [[paper](https://aclanthology.org/2023.acl-long.320.pdf)]

Chain of Thought Prompting Elicits Knowledge Augmentation,2023.[[paper](https://aclanthology.org/2023.findings-acl.408.pdf)]

### * Hallucination

Evaluating Hallucinations in Chinese Large Language Models,2023. [[paper](https://arxiv.org/abs/2310.03368)]

TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization,2024.[[paper](https://arxiv.org/abs/2402.13249)]

Exploring and Evaluating Hallucinations in LLM-Powered Code Generation,2024. [[paper](https://arxiv.org/abs/2404.00971)]

UHGEval: Benchmarking the Hallucination of
Chinese Large Language Models via Unconstrained Generation,2024.[[paper](https://arxiv.org/abs/2311.15296)]

Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models,2023.[[paper](https://dl.acm.org/doi/pdf/10.1145/3583780.3614905)]

The Internal State of an LLM Knows When It's Lying,2023. [[paper](https://arxiv.org/abs/2304.13734)]

Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation,2023. [[ICLR](https://openreview.net/pdf?id=VD-AYtP0dve)]


### * LLM Interpretation

Rethinking Interpretability in the Era of Large Language Models,2024.[[paper](https://arxiv.org/abs/2402.01761)]

### * LLM using Tools
Toolformer: Language Models Can Teach Themselves to Use Tools, 2024. [[Neurips](https://papers.nips.cc/paper_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html)]

# Parameter-Efficient Fine-Tuning

Blog[[Link](https://spaces.ac.cn/archives/9590)]

LoRA: Low-Rank Adaptation of Large Language Models,2021.[[paper](https://arxiv.org/abs/2106.09685)]

MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient Fine-Tuning,2024.[[ACL](https://aclanthology.org/2024.acl-long.168)]

# Other

DeepChannel: Salience Estimation by Contrastive Learning
for Extractive Document Summarization,2018.[[paper](https://arxiv.org/abs/1811.02394)]

Element-aware Summarization with Large Language Models:
Expert-aligned Evaluation and Chain-of-Thought Method,2023. [[paper](https://aclanthology.org/2023.acl-long.482.pdf)]
